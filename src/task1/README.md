
## üìå Task 1 Instructions: Dead Sea Scrolls

All scripts for this task are located in `src/task1/scripts`.

To begin, download the `monkbrill/` folder and place it at the root of the repository. This folder contains the Hebrew character images needed for training.

Then, run the script that performs data cleaning. This will create a new folder called `monkbrill_clean/` at the root, containing the cleaned characters.

Next, download the noise maps from the provided Google Drive folder. Place them inside a new folder named `noise_maps/` at the root. Then, run the script that binarizes these noise maps. This will produce a `binarized/` subfolder inside `noise_maps/`.

You will also need to download the ImageMorph tool from its GitHub repository at https://github.com/GrHound/imagemorph.c. This tool is used for character morphing and is referenced in the data augmentation pipeline.

The `translation.py` script can be used to translate Aesop‚Äôs fables and any other `.txt` files of your choice. Note that the translated `.txt` files are already included in the `text_files/` folder at the root of the repository. If you want to use other files, you will need to modify the code to define whether the new text files will be used for training or validation in the YOLO detection step.

To generate synthetic scroll images, run the `create_text_scrolls.py` and `create_random_scrolls.py` scripts. One script creates scroll images using the provided Hebrew `.txt` files, while the other creates random scrolls for augmentation purposes.

After the scroll images are created, use the `line_segmentation.py` script to segment full scroll images into smaller images containing individual lines. This step produces a new folder called `segmented_scrolls/`, which will be used to train the YOLO model.

Once you have segmented line images, train the YOLO detector using the provided training script.

After training, you can run the prediction script by providing the path to the trained YOLO model along with the input scroll image. If a ground truth label is available for that image, you can also provide it to compare the model's prediction with the ground truth.

Finally, you can visualize the predicted bounding boxes by using the `visualise_bounding_boxes.py` script. This script takes a scroll image and a label file as input and overlays the ground truth bounding boxes on the image for inspection.

---

## üìÅ Project Final Layout

- `monkbrill/` ‚Äî Original Hebrew character dataset (to be downloaded manually)
- `monkbrill_clean/` ‚Äî Cleaned characters (generated by script)
- `noise_maps/` ‚Äî Folder for noise maps (to be downloaded)
  - `binarized/` ‚Äî Binarized version of noise maps (generated by script)
- `text_files/` ‚Äî Translated Hebrew text files (already provided)

- `generated_scrolls/` ‚Äî Folder with the generated scrolls from text (eg. bible_train.txt)
- `synthetic_scrolls/` ‚Äî Folder with the synthetic random text scrolls
- `segmented_scrolls/` ‚Äî Contains segmented line images (generated by script)

- `src/task1/scripts/` ‚Äî All scripts related to Task 1
- `Makefile` ‚Äî For setting up environment, installing dependencies, and cleaning
- `requirements.txt` ‚Äî Code requirements

---

